<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>StatLab Articles</title>
    <link>/</link>
    <description>Recent content on StatLab Articles</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>An Introduction to Analyzing Twitter Data with R</title>
      <link>/2019/05/03/an-introduction-to-analyzing-twitter-data-with-r/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/03/an-introduction-to-analyzing-twitter-data-with-r/</guid>
      <description>In this article, I will walk you through why a researcher or professional might find data from Twitter useful, explain how to collect the relevant tweets and information from Twitter in R, and then finish by demonstrating a few useful analyses (along with accompanying cleaning) you might perform on your Twitter data.
Part One: Why Twitter Data?To begin, we should ask: why would someone be interested in using data from Twitter?</description>
    </item>
    
    <item>
      <title>Getting Started with Multiple Imputation in R</title>
      <link>/2019/05/01/getting-started-with-multiple-imputation-in-r/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/01/getting-started-with-multiple-imputation-in-r/</guid>
      <description>Whenever we are dealing with a dataset, we almost always run into a problem that may decrease our confidence in the results that we are getting - missing data! Examples of missing data can be found in surveys - where respondents intentionally refrained from answering a question, didn’t answer a question because it is not applicable to them, or simply forgot to give an answer. Or our dataset on trade in agricultural products for country-pairs over years could suffer from missing data as some countries fail to report their accounts for certain years.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Wed, 17 Apr 2019 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>The UVA StatLab publishes short articles and tutorials on various statistical topics. We try our best to provide clear and accessible explanations. If you have questions, comments or requests, we want to hear from you: statlab@virginia.edu</description>
    </item>
    
    <item>
      <title>Assessing Type S and Type M Errors</title>
      <link>/2018/10/31/assessing-type-s-and-type-m-errors/</link>
      <pubDate>Wed, 31 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/31/assessing-type-s-and-type-m-errors/</guid>
      <description>The paper Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors by Andrew Gelman and John Carlin introduces the idea of performing design calculations to help prevent researchers from being misled by statistically significant results in studies with small samples and/or noisy measurements. The main idea is that researchers often overestimate effect sizes in power calculations and collect noisy (ie, highly variable) data, which can make statistically significant results suspect.</description>
    </item>
    
    <item>
      <title>Interpreting Log Transformations in a Linear Model</title>
      <link>/2018/08/17/interpreting-log-transformations-in-a-linear-model/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/17/interpreting-log-transformations-in-a-linear-model/</guid>
      <description>Log transformations are often recommended for skewed data, such as monetary measures or certain biological and demographic measures. Log transforming data usually has the effect of spreading out clumps of data and bringing together spread-out data. For example, below is a histogram of the areas of all 50 US states. It is skewed to the right due to Alaska, California, Texas and a few others.
hist(state.area)After a log transformation, notice the histogram is more or less symmetric.</description>
    </item>
    
    <item>
      <title>Getting Started with Matching Methods</title>
      <link>/2018/04/24/getting-started-with-matching-methods/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/24/getting-started-with-matching-methods/</guid>
      <description>A frequent research question is whether or not some “treatment” causes an effect. For example, does taking aspirin daily reduce the chance of a heart attack? Does more sleep lead to better academic performance for teenagers? Does smoking increase the risk of chronic obstructive pulmonary disease (COPD)?
To truly answer such questions, we need a time machine and a lack of ethics. We would need to be able to take a subject and, say, make him or her smoke for several years and observe whether or not they get COPD.</description>
    </item>
    
    <item>
      <title>Getting Started with Moderated Mediation</title>
      <link>/2018/03/02/getting-started-with-moderated-mediation/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/02/getting-started-with-moderated-mediation/</guid>
      <description>In a previous post we demonstrated how to perform a basic mediation analysis. In this post we look at performing a moderated mediation analysis.
The basic idea is that a mediator may depend on another variable called a “moderator”. For example, in our mediation analysis post we hypothesized that self-esteem was a mediator of student grades on the effect of student happiness. We illustrate this below with a path diagram.</description>
    </item>
    
    <item>
      <title>Getting started with Multivariate Multiple Regression</title>
      <link>/2017/10/27/getting-started-with-multivariate-multiple-regression/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/10/27/getting-started-with-multivariate-multiple-regression/</guid>
      <description>Multivariate Multiple Regression is the method of modeling multiple responses, or dependent variables, with a single set of predictor variables. For example, we might want to model both math and reading SAT scores as a function of gender, race, parent income, and so forth. This allows us to evaluate the relationship of, say, gender with each score. You may be thinking, “why not just run separate regressions for each dependent variable?</description>
    </item>
    
    <item>
      <title>Visualizing the Effects of Proportional-Odds Logistic Regression</title>
      <link>/2017/05/10/visualizing-the-effects-of-proportional-odds-logistic-regression/</link>
      <pubDate>Wed, 10 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/10/visualizing-the-effects-of-proportional-odds-logistic-regression/</guid>
      <description>Proportional-odds logistic regression is often used to model an ordered categorical response. By “ordered”, we mean categories that have a natural ordering, such as “Disagree”, “Neutral”, “Agree”, or “Everyday”, “Some days”, “Rarely”, “Never”. For a primer on proportional-odds logistic regression, see our post, Fitting and Interpreting a Proportional Odds Model. In this post we demonstrate how to visualize a proportional-odds model in R.
To begin, we load the effects package.</description>
    </item>
    
    <item>
      <title>Getting started with the purrr package in R</title>
      <link>/2017/04/14/getting-started-with-the-purrr-package-in-r/</link>
      <pubDate>Fri, 14 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/04/14/getting-started-with-the-purrr-package-in-r/</guid>
      <description>If you’re wondering what exactly the purrr package does, then this blog post is for you.
Before we get started, we should mention the Iteration chapter in R for Data Science by Garrett Grolemund and Hadley Wickham. We think this is the most thorough and extensive introduction to the purrr package currently available (at least at the time of this writing.) Wickham is one of the authors of the purrr package and he spends a good deal of the chapter clearly explaining how it works.</description>
    </item>
    
    <item>
      <title>Working with dates and time in R using the lubridate package</title>
      <link>/2017/01/11/working-with-dates-and-time-in-r-using-the-lubridate-package/</link>
      <pubDate>Wed, 11 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/01/11/working-with-dates-and-time-in-r-using-the-lubridate-package/</guid>
      <description>Sometimes we have data with dates and/or times that we want to manipulate or summarize. A common example in the health sciences is time-in-study. A subject may enter a study on Feb 12, 2008 and exit on November 4, 2009. How many days was the person in the study? (Don’t forget 2008 was a leap year; February had 29 days.) What was the median time-in-study for all subjects?
Another example are experiments that time participants performing an activity, applies a treatment to certain members, and then re-times the activity.</description>
    </item>
    
  </channel>
</rss>